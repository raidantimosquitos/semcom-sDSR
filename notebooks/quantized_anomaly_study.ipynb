{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantized anomaly study (Part 2)\n",
    "\n",
    "Encode normal and anomalous test spectrograms with Stage 1 VQ-VAE; compare code-index usage (normal vs anomaly), spatial \"where indices change\" map, and optional z-distance. Output summary for mask priors and code-preference in the anomaly generation module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: data and Stage 1 VQ-VAE\n",
    "\n",
    "Load test data grouped by machine_id and label; load trained VQ-VAE per machine type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "_cwd = Path(\".\").resolve()\n",
    "PROJECT_ROOT = _cwd.parent if _cwd.name == \"notebooks\" else _cwd\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data.dataset import DCASE2020Task2LogMelDataset, DCASE2020Task2TestDataset\n",
    "from src.models.vq_vae.autoencoders import VQ_VAE_2Layer\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / \"../data/dcase2020-task2-dev-dataset\"\n",
    "if not DATA_PATH.exists():\n",
    "    DATA_PATH = PROJECT_ROOT / \"data/dcase2020-task2-dev-dataset\"\n",
    "CKPT_DIR = PROJECT_ROOT / \"checkpoints\"\n",
    "MACHINE_TYPES = [\"fan\", \"pump\"]\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "MAX_SAMPLES_PER_ID = 200\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_grouped(data_path: Path, machine_type: str):\n",
    "    train_ds = DCASE2020Task2LogMelDataset(\n",
    "        root=str(data_path), machine_type=machine_type, normalize=True\n",
    "    )\n",
    "    _, _, n_mels, T = train_ds.data.shape\n",
    "    test_ds = DCASE2020Task2TestDataset(\n",
    "        root=str(data_path),\n",
    "        machine_type=machine_type,\n",
    "        mean=train_ds.mean,\n",
    "        std=train_ds.std,\n",
    "        target_T=train_ds.target_T,\n",
    "    )\n",
    "    grouped = defaultdict(lambda: {0: [], 1: []})\n",
    "    for idx in range(len(test_ds)):\n",
    "        spec, label, machine_id = test_ds[idx]\n",
    "        if spec.dim() == 3:\n",
    "            spec = spec.squeeze(0)\n",
    "        grouped[machine_id][label].append((spec.numpy(), idx))\n",
    "    return train_ds, test_ds, grouped, n_mels, T\n",
    "\n",
    "def load_vq(machine_type: str, n_mels: int, T: int):\n",
    "    vq = VQ_VAE_2Layer(\n",
    "        num_hiddens=128,\n",
    "        num_residual_layers=2,\n",
    "        num_residual_hiddens=64,\n",
    "        num_embeddings=(1024, 4096),\n",
    "        embedding_dim=128,\n",
    "        commitment_cost=0.25,\n",
    "        decay=0.99,\n",
    "    )\n",
    "    ckpt = CKPT_DIR / \"stage1\" / machine_type / f\"stage1_{machine_type}_best.pt\"\n",
    "    if ckpt.exists():\n",
    "        state = torch.load(ckpt, map_location=\"cpu\", weights_only=True)\n",
    "        vq.load_state_dict(state[\"model_state_dict\"])\n",
    "    return vq.to(DEVICE).eval()\n",
    "\n",
    "data_by_type = {}\n",
    "for mt in MACHINE_TYPES:\n",
    "    try:\n",
    "        train_ds, test_ds, grouped, n_mels, T = load_test_grouped(DATA_PATH, mt)\n",
    "        data_by_type[mt] = {\"train_ds\": train_ds, \"test_ds\": test_ds, \"grouped\": grouped, \"n_mels\": n_mels, \"T\": T}\n",
    "        print(f\"{mt}: n_mels={n_mels}, T={T}, IDs={sorted(grouped.keys())}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Skip {mt}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encode and collect code indices (normal vs anomaly)\n",
    "\n",
    "For each machine type: run encode_with_prequant on normal and anomalous spectrograms; get codebook indices from VQ encodings (argmax over encodings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_indices(vq, z: torch.Tensor, vq_module: torch.nn.Module) -> torch.Tensor:\n",
    "    \"\"\"Return (B, H, W) long tensor of codebook indices.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        _, quantized, _, encodings = vq_module(z)\n",
    "    B, C, H, W = z.shape\n",
    "    indices = encodings.argmax(dim=1).view(B, H, W)\n",
    "    return indices.cpu()\n",
    "\n",
    "def collect_indices_and_z(vq, grouped, machine_type: str, n_mels: int, T: int):\n",
    "    \"\"\"Collect code indices and z for normal (0) and anomaly (1) per machine_id.\"\"\"\n",
    "    out = {}\n",
    "    for mid in sorted(grouped.keys()):\n",
    "        norm_list = grouped[mid][0][:MAX_SAMPLES_PER_ID]\n",
    "        anom_list = grouped[mid][1][:MAX_SAMPLES_PER_ID]\n",
    "        out[mid] = {\"indices_bot_n\": [], \"indices_bot_a\": [], \"indices_top_n\": [], \"indices_top_a\": [],\n",
    "                   \"z_bot_n\": [], \"z_bot_a\": [], \"q_bot_n\": [], \"q_bot_a\": []}\n",
    "        for label, arr_list in [(0, norm_list), (1, anom_list)]:\n",
    "            if not arr_list:\n",
    "                continue\n",
    "            arr = np.stack([a[0] for a in arr_list])\n",
    "            x = torch.from_numpy(arr).float().unsqueeze(1).to(DEVICE)\n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "                batch = x[i : i + BATCH_SIZE]\n",
    "                with torch.no_grad():\n",
    "                    q_bot, q_top, z_bot, z_top = vq.encode_with_prequant(batch)\n",
    "                idx_bot = get_code_indices(vq, z_bot, vq._vq_bot)\n",
    "                idx_top = get_code_indices(vq, z_top, vq._vq_top)\n",
    "                if label == 0:\n",
    "                    out[mid][\"indices_bot_n\"].append(idx_bot)\n",
    "                    out[mid][\"indices_top_n\"].append(idx_top)\n",
    "                    out[mid][\"z_bot_n\"].append(z_bot.cpu())\n",
    "                    out[mid][\"q_bot_n\"].append(q_bot.cpu())\n",
    "                else:\n",
    "                    out[mid][\"indices_bot_a\"].append(idx_bot)\n",
    "                    out[mid][\"indices_top_a\"].append(idx_top)\n",
    "                    out[mid][\"z_bot_a\"].append(z_bot.cpu())\n",
    "                    out[mid][\"q_bot_a\"].append(q_bot.cpu())\n",
    "        for k in list(out[mid].keys()):\n",
    "            if out[mid][k]:\n",
    "                out[mid][k] = torch.cat(out[mid][k], dim=0)\n",
    "            else:\n",
    "                out[mid][k] = None\n",
    "    return out\n",
    "\n",
    "results_by_type = {}\n",
    "for mt, data in data_by_type.items():\n",
    "    vq = load_vq(mt, data[\"n_mels\"], data[\"T\"])\n",
    "    results_by_type[mt] = collect_indices_and_z(vq, data[\"grouped\"], mt, data[\"n_mels\"], data[\"T\"])\n",
    "    print(f\"{mt}: collected indices per ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Code usage histograms (normal vs anomaly)\n",
    "\n",
    "Per machine_id: histogram of code indices for normal vs anomalous. Identify codes over-used in anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_usage_histogram(indices: torch.Tensor, num_codes: int) -> np.ndarray:\n",
    "    \"\"\"(B, H, W) -> (num_codes,) counts.\"\"\"\n",
    "    if indices is None or indices.numel() == 0:\n",
    "        return np.zeros(num_codes)\n",
    "    flat = indices.view(-1).numpy()\n",
    "    counts = np.bincount(flat, minlength=num_codes)\n",
    "    return counts[:num_codes]\n",
    "\n",
    "def plot_code_usage(results, machine_type: str, machine_id: str, num_embeddings_bot: int, num_embeddings_top: int):\n",
    "    r = results[machine_id]\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    for level, name, N in [(\"bot\", \"bottom\", num_embeddings_bot), (\"top\", \"top\", num_embeddings_top)]:\n",
    "        cn = code_usage_histogram(r[f\"indices_{level}_n\"], N)\n",
    "        ca = code_usage_histogram(r[f\"indices_{level}_a\"], N)\n",
    "        axes[0 if level == \"bot\" else 1, 0].bar(np.arange(min(100, N)), cn[:100], alpha=0.7, label=\"normal\")\n",
    "        axes[0 if level == \"bot\" else 1, 0].set_title(f\"Code usage {name} (first 100)\")\n",
    "        axes[0 if level == \"bot\" else 1, 0].legend()\n",
    "        diff = ca.astype(float) - cn.astype(float)\n",
    "        axes[0 if level == \"bot\" else 1, 1].bar(np.arange(min(100, N)), diff[:100], color=\"orange\", alpha=0.8)\n",
    "        axes[0 if level == \"bot\" else 1, 1].set_title(f\"Anomaly − normal usage {name}\")\n",
    "    plt.suptitle(f\"{machine_type} / {machine_id}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "NUM_EMBEDDINGS = (1024, 4096)\n",
    "for mt in MACHINE_TYPES:\n",
    "    if mt not in results_by_type:\n",
    "        continue\n",
    "    for mid in sorted(results_by_type[mt].keys()):\n",
    "        plot_code_usage(results_by_type[mt], mt, mid, NUM_EMBEDDINGS[1], NUM_EMBEDDINGS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spatial map: where do code indices change?\n",
    "\n",
    "For each machine_id, average over anomalous samples: proportion of samples where index differs from mean normal index at that position (or use mean |index_anom − index_normal|)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_change_map(results, machine_id: str) -> tuple[np.ndarray | None, np.ndarray | None]:\n",
    "    \"\"\"Return (H, W) map of mean absolute index change (bot, top) or None.\"\"\"\n",
    "    r = results[machine_id]\n",
    "    idx_bot_n = r[\"indices_bot_n\"]\n",
    "    idx_bot_a = r[\"indices_bot_a\"]\n",
    "    idx_top_n = r[\"indices_top_n\"]\n",
    "    idx_top_a = r[\"indices_top_a\"]\n",
    "    if idx_bot_n is None or idx_bot_a is None or idx_bot_n.shape[0] == 0 or idx_bot_a.shape[0] == 0:\n",
    "        return None, None\n",
    "    mean_bot_n = idx_bot_n.float().mean(dim=0)\n",
    "    mean_top_n = idx_top_n.float().mean(dim=0)\n",
    "    change_bot = (idx_bot_a.float() - mean_bot_n.unsqueeze(0)).abs().mean(dim=0).numpy()\n",
    "    change_top = (idx_top_a.float() - mean_top_n.unsqueeze(0)).abs().mean(dim=0).numpy()\n",
    "    return change_bot, change_top\n",
    "\n",
    "def plot_spatial_change(results, machine_type: str, machine_id: str):\n",
    "    change_bot, change_top = spatial_change_map(results, machine_id)\n",
    "    if change_bot is None:\n",
    "        return\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    axes[0].imshow(change_bot, aspect=\"auto\", origin=\"lower\", cmap=\"hot\")\n",
    "    axes[0].set_title(f\"Mean |index_anom − mean_index_normal| bottom ({machine_type} / {machine_id})\")\n",
    "    axes[0].set_xlabel(\"Time (q)\")\n",
    "    axes[0].set_ylabel(\"Mel (q)\")\n",
    "    axes[1].imshow(change_top, aspect=\"auto\", origin=\"lower\", cmap=\"hot\")\n",
    "    axes[1].set_title(\"Top\")\n",
    "    axes[1].set_xlabel(\"Time (q)\")\n",
    "    axes[1].set_ylabel(\"Mel (q)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for mt in MACHINE_TYPES:\n",
    "    if mt not in results_by_type:\n",
    "        continue\n",
    "    for mid in sorted(results_by_type[mt].keys()):\n",
    "        plot_spatial_change(results_by_type[mt], mt, mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Z vs codebook distance (optional)\n",
    "\n",
    "For anomalous samples, how far is z from its quantized code? Mean residual per position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_code_distance(z: torch.Tensor, q: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"(B, C, H, W) -> (B, H, W) L2 distance.\"\"\"\n",
    "    return (z - q).pow(2).sum(dim=1).sqrt()\n",
    "\n",
    "def plot_z_residual(results, machine_type: str, machine_id: str):\n",
    "    r = results[machine_id]\n",
    "    z_a = r[\"z_bot_a\"]\n",
    "    q_a = r[\"q_bot_a\"]\n",
    "    if z_a is None or q_a is None or z_a.shape[0] == 0:\n",
    "        return\n",
    "    dist = z_code_distance(z_a, q_a)\n",
    "    mean_dist = dist.mean(dim=0).numpy()\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    im = ax.imshow(mean_dist, aspect=\"auto\", origin=\"lower\", cmap=\"hot\")\n",
    "    ax.set_title(f\"Mean |z − q| anomaly bottom ({machine_type} / {machine_id})\")\n",
    "    ax.set_xlabel(\"Time (q)\")\n",
    "    ax.set_ylabel(\"Mel (q)\")\n",
    "    plt.colorbar(im, ax=ax, label=\"L2\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for mt in MACHINE_TYPES:\n",
    "    if mt not in results_by_type:\n",
    "        continue\n",
    "    for mid in sorted(results_by_type[mt].keys()):\n",
    "        plot_z_residual(results_by_type[mt], mt, mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary table: preferred q regions, codes over-used in anomalies, strength\n",
    "\n",
    "Per machine type / ID: peak of spatial change map (preferred q regions for masks); codes with positive anomaly−normal usage (over-used in anomalies); suggested strength range from z-distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = []\n",
    "for mt in MACHINE_TYPES:\n",
    "    if mt not in results_by_type:\n",
    "        continue\n",
    "    for mid in sorted(results_by_type[mt].keys()):\n",
    "        r = results_by_type[mt][mid]\n",
    "        change_bot, change_top = spatial_change_map(results_by_type[mt], mid)\n",
    "        row = {\"machine_type\": mt, \"machine_id\": mid}\n",
    "        if change_bot is not None:\n",
    "            peak = np.unravel_index(np.argmax(change_bot), change_bot.shape)\n",
    "            Hq, Wq = change_bot.shape\n",
    "            row[\"q_peak_bot\"] = f\"mel_q={peak[0]}/{Hq}, time_q={peak[1]}/{Wq}\"\n",
    "        else:\n",
    "            row[\"q_peak_bot\"] = \"N/A\"\n",
    "        cn_bot = code_usage_histogram(r[\"indices_bot_n\"], 4096) if r[\"indices_bot_n\"] is not None else np.zeros(4096)\n",
    "        ca_bot = code_usage_histogram(r[\"indices_bot_a\"], 4096) if r[\"indices_bot_a\"] is not None else np.zeros(4096)\n",
    "        diff = ca_bot - cn_bot\n",
    "        overused = np.where(diff > 0)[0]\n",
    "        row[\"n_codes_overused_bot\"] = len(overused)\n",
    "        row[\"top5_overused_bot\"] = np.argsort(-diff)[:5].tolist() if len(overused) else []\n",
    "        summary_table.append(row)\n",
    "for row in summary_table:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
