{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage1 t-SNE Comparison\n",
        "\n",
        "Load the stage1 VQ-VAE checkpoint, extract pre-quant (z_top, z_bot) and post-quant (q_top, q_bot) feature maps for a stratified subset of a single machine type, run t-SNE, and compare clustering before vs after quantization. Also plot code usage histograms for coarse (top) and fine (bottom) resolutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n",
        "\n",
        "Paths, imports, and config. `N_SAMPLES` (e.g. 800) balances t-SNE runtime and cluster visibility; perplexity 30 is a reasonable default for N≈800."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu, N_SAMPLES=800\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "_cwd = Path(\".\").resolve()\n",
        "PROJECT_ROOT = _cwd.parent if _cwd.name == \"notebooks\" else _cwd\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "CKPT_DIR = PROJECT_ROOT / \"checkpoints\"\n",
        "DATA_PATH = \"/mnt/ssd/LaCie/dcase2020-task2-dev-dataset\"  # set to your DCASE root\n",
        "MACHINE_TYPE = \"fan\"\n",
        "STAGE1_CKPT = \"checkpoints/stage1/fan/stage1_ToyCar+ToyConveyor+fan+pump+slider+valve_final.pt\"  # or stage1_{machine_type}_iter_*.pt\n",
        "STAGE1_CKPT = CKPT_DIR / \"stage1\" / MACHINE_TYPE / \"stage1_ToyCar+ToyConveyor+fan+pump+slider+valve_final.pt\"\n",
        "\n",
        "N_SAMPLES = 800   # 500–1000 recommended for t-SNE; stratified by machine_id\n",
        "BATCH_SIZE = 64\n",
        "TSNE_PERPLEXITY = 30\n",
        "TSNE_RANDOM_STATE = 42\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DEVICE = \"cpu\"\n",
        "print(f\"Device: {DEVICE}, N_SAMPLES={N_SAMPLES}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load dataset and stratified subset\n",
        "\n",
        "Group indices by `machine_id`, then sample proportionally up to `N_SAMPLES` so each appliance instance is represented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padded T: 313 → 320 (target: 320)\n",
            "DCASE2020Task2LogMelDataset: fan | 3675 spectrograms, shape (3675, 1, 128, 320) | IDs: ['id_00', 'id_02', 'id_04', 'id_06'] | 0.60 GB in RAM\n",
            "Dataset: 3675 samples, n_mels=128, T=320, machine_ids=['id_00', 'id_02', 'id_04', 'id_06']\n",
            "Subset: 800 indices\n"
          ]
        }
      ],
      "source": [
        "from src.data.dataset import DCASE2020Task2LogMelDataset\n",
        "\n",
        "dataset = DCASE2020Task2LogMelDataset(\n",
        "    root=DATA_PATH,\n",
        "    machine_type=MACHINE_TYPE,\n",
        "    normalize=True,\n",
        ")\n",
        "\n",
        "_, _, n_mels, T = dataset.data.shape\n",
        "print(f\"Dataset: {len(dataset)} samples, n_mels={n_mels}, T={T}, machine_ids={dataset.machine_ids}\")\n",
        "\n",
        "def stratified_sample_indices(dataset, n_samples: int, seed: int = 42):\n",
        "    by_id = defaultdict(list)\n",
        "    for i in range(len(dataset)):\n",
        "        by_id[dataset._machine_id_strs[i]].append(i)\n",
        "    rng = random.Random(seed)\n",
        "    target_per_id = max(1, n_samples // len(by_id))\n",
        "    indices = []\n",
        "    for mid, idx_list in sorted(by_id.items()):\n",
        "        k = min(len(idx_list), target_per_id)\n",
        "        indices.extend(rng.sample(idx_list, k))\n",
        "    if len(indices) > n_samples:\n",
        "        indices = rng.sample(indices, n_samples)\n",
        "    elif len(indices) < n_samples:\n",
        "        short = n_samples - len(indices)\n",
        "        extra = []\n",
        "        for mid, idx_list in sorted(by_id.items()):\n",
        "            remaining = [i for i in idx_list if i not in indices]\n",
        "            extra.extend(rng.sample(remaining, min(short, len(remaining))))\n",
        "            if len(extra) >= short:\n",
        "                break\n",
        "        indices.extend(extra[:short])\n",
        "    return indices\n",
        "\n",
        "subset_indices = stratified_sample_indices(dataset, N_SAMPLES, seed=RANDOM_SEED)\n",
        "subset = Subset(dataset, subset_indices)\n",
        "loader = DataLoader(subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "print(f\"Subset: {len(subset_indices)} indices\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load stage1 model\n",
        "\n",
        "Build VQ-VAE with same hyperparameters as `scripts/train.py` and load checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded checkpoint: /home/lucash/Documents/NTUST/Research/papers/semantic-communication-networks/audDSR/checkpoints/stage1/fan/stage1_ToyCar+ToyConveyor+fan+pump+slider+valve_final.pt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "VQ_VAE_2Layer(\n",
              "  (_encoder_bot): EncoderBot(\n",
              "    (_conv1): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (_conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (_conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (_residual): ResidualStack(\n",
              "      (_layers): ModuleList(\n",
              "        (0-1): 2 x Residual(\n",
              "          (_block): Sequential(\n",
              "            (0): ReLU()\n",
              "            (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (2): ReLU()\n",
              "            (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (_encoder_top): EncoderTop(\n",
              "    (_conv1): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (_conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (_residual): ResidualStack(\n",
              "      (_layers): ModuleList(\n",
              "        (0-1): 2 x Residual(\n",
              "          (_block): Sequential(\n",
              "            (0): ReLU()\n",
              "            (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (2): ReLU()\n",
              "            (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (_pre_vq_conv_top): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (_pre_vq_conv_bot): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (_vq_top): VectorQuantizerEMA(\n",
              "    (_embedding): Embedding(4096, 128)\n",
              "  )\n",
              "  (_vq_bot): VectorQuantizerEMA(\n",
              "    (_embedding): Embedding(4096, 128)\n",
              "  )\n",
              "  (_decoder_top): DecoderTop(\n",
              "    (_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (_residual): ResidualStack(\n",
              "      (_layers): ModuleList(\n",
              "        (0-1): 2 x Residual(\n",
              "          (_block): Sequential(\n",
              "            (0): ReLU()\n",
              "            (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (2): ReLU()\n",
              "            (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (_conv_trans): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  )\n",
              "  (_decoder_bot): DecoderBot(\n",
              "    (_conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (_residual): ResidualStack(\n",
              "      (_layers): ModuleList(\n",
              "        (0-1): 2 x Residual(\n",
              "          (_block): Sequential(\n",
              "            (0): ReLU()\n",
              "            (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (2): ReLU()\n",
              "            (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (_conv_trans1): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (_conv_trans2): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from src.models.vq_vae.autoencoders import VQ_VAE_2Layer\n",
        "\n",
        "def build_vq_vae(n_mels: int, T: int) -> VQ_VAE_2Layer:\n",
        "    return VQ_VAE_2Layer(\n",
        "        num_hiddens=128,\n",
        "        num_residual_layers=2,\n",
        "        num_residual_hiddens=64,\n",
        "        num_embeddings=(4096, 4096),\n",
        "        embedding_dim=128,\n",
        "        commitment_cost=0.25,\n",
        "        decay=0.99,\n",
        "    )\n",
        "\n",
        "vq_vae = build_vq_vae(n_mels, T)\n",
        "if STAGE1_CKPT.exists():\n",
        "    ckpt = torch.load(STAGE1_CKPT, map_location=\"cpu\", weights_only=False)\n",
        "    vq_vae.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "    print(f\"Loaded checkpoint: {STAGE1_CKPT}\")\n",
        "else:\n",
        "    print(\"Warning: Stage1 checkpoint not found; using random weights.\")\n",
        "vq_vae = vq_vae.to(DEVICE)\n",
        "vq_vae.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Extract features\n",
        "\n",
        "Run batches through `encode_with_prequant`, global average pool (B, C, H, W) → (B, C), and collect z_top, z_bot, q_top, q_bot plus machine_id for each sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pool_spatial(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"(B, C, H, W) -> (B, C)\"\"\"\n",
        "    return x.mean(dim=(2, 3))\n",
        "\n",
        "list_z_top, list_z_bot, list_q_top, list_q_bot = [], [], [], []\n",
        "list_machine_ids = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in loader:\n",
        "        if isinstance(batch, (list, tuple)):\n",
        "            x = batch[0]\n",
        "            mid_batch = batch[2]  # machine_id per sample\n",
        "        else:\n",
        "            x = batch\n",
        "            mid_batch = [\"unknown\"] * x.shape[0]\n",
        "        x = x.to(DEVICE)\n",
        "        q_bot, q_top, z_bot, z_top = vq_vae.encode_with_prequant(x)\n",
        "        list_z_top.append(pool_spatial(z_top).cpu())\n",
        "        list_z_bot.append(pool_spatial(z_bot).cpu())\n",
        "        list_q_top.append(pool_spatial(q_top).cpu())\n",
        "        list_q_bot.append(pool_spatial(q_bot).cpu())\n",
        "        list_machine_ids.extend(mid_batch)\n",
        "\n",
        "Z_top = torch.cat(list_z_top, dim=0).numpy()\n",
        "Z_bot = torch.cat(list_z_bot, dim=0).numpy()\n",
        "Q_top = torch.cat(list_q_top, dim=0).numpy()\n",
        "Q_bot = torch.cat(list_q_bot, dim=0).numpy()\n",
        "machine_ids_subset = list_machine_ids\n",
        "\n",
        "N = Z_top.shape[0]\n",
        "print(f\"Features: Z_top {Z_top.shape}, Z_bot {Z_bot.shape}, Q_top {Q_top.shape}, Q_bot {Q_bot.shape}, N={N}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Code usage histograms (top and bottom resolutions)\n",
        "\n",
        "For each sample we have quantized maps q_top (coarse) and q_bot (fine). We infer the code index at each spatial position by nearest codebook lookup, then aggregate counts across the subset and plot which codes are used most."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_code_usage_counts(vq_vae, loader, device):\n",
        "    \"\"\"Return (counts_top, counts_bot) as 1D arrays of length num_embeddings_top/bot.\"\"\"\n",
        "    emb_top = vq_vae._vq_top._embedding.weight  # (num_emb_top, dim)\n",
        "    emb_bot = vq_vae._vq_bot._embedding.weight  # (num_emb_bot, dim)\n",
        "    num_top = emb_top.shape[0]\n",
        "    num_bot = emb_bot.shape[0]\n",
        "    counts_top = np.zeros(num_top, dtype=np.int64)\n",
        "    counts_bot = np.zeros(num_bot, dtype=np.int64)\n",
        "    emb_top_np = emb_top.detach().cpu().numpy()\n",
        "    emb_bot_np = emb_bot.detach().cpu().numpy()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            if isinstance(batch, (list, tuple)):\n",
        "                x = batch[0]\n",
        "            else:\n",
        "                x = batch\n",
        "            x = x.to(device)\n",
        "            q_bot, q_top, _, _ = vq_vae.encode_with_prequant(x)\n",
        "            # q_top (B, C, H, W) -> (B*H*W, C)\n",
        "            flat_top = q_top.permute(0, 2, 3, 1).reshape(-1, q_top.shape[1]).cpu().numpy()\n",
        "            flat_bot = q_bot.permute(0, 2, 3, 1).reshape(-1, q_bot.shape[1]).cpu().numpy()\n",
        "            # Nearest codebook index: argmin of squared distances\n",
        "            # (N, C) @ (C, K) -> (N, K); dist^2 = ||a||^2 + ||b||^2 - 2 a.b\n",
        "            d_top = flat_top.dot(emb_top_np.T)\n",
        "            d_top = -2 * d_top + (emb_top_np ** 2).sum(axis=1)\n",
        "            idx_top = np.argmin(d_top, axis=1)\n",
        "            d_bot = flat_bot.dot(emb_bot_np.T)\n",
        "            d_bot = -2 * d_bot + (emb_bot_np ** 2).sum(axis=1)\n",
        "            idx_bot = np.argmin(d_bot, axis=1)\n",
        "            for i in idx_top:\n",
        "                counts_top[i] += 1\n",
        "            for i in idx_bot:\n",
        "                counts_bot[i] += 1\n",
        "    return counts_top, counts_bot\n",
        "\n",
        "counts_top, counts_bot = get_code_usage_counts(vq_vae, loader, DEVICE)\n",
        "print(f\"Top (coarse) codes: {counts_top.shape[0]} total, {np.sum(counts_top > 0)} used\")\n",
        "print(f\"Bottom (fine) codes: {counts_bot.shape[0]} total, {np.sum(counts_bot > 0)} used\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_code_usage_histograms(counts_top, counts_bot, top_k=80):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    # Sort by count descending and take top_k\n",
        "    order_top = np.argsort(counts_top)[::-1]\n",
        "    order_bot = np.argsort(counts_bot)[::-1]\n",
        "    x_top = np.arange(min(top_k, len(counts_top)))\n",
        "    axes[0].bar(x_top, counts_top[order_top[:top_k]], color=\"steelblue\", alpha=0.8)\n",
        "    axes[0].set_title(f\"Coarse (top) code usage — top {top_k} most used codes\")\n",
        "    axes[0].set_xlabel(\"Rank (by usage)\")\n",
        "    axes[0].set_ylabel(\"Count\")\n",
        "\n",
        "    x_bot = np.arange(min(top_k, len(counts_bot)))\n",
        "    axes[1].bar(x_bot, counts_bot[order_bot[:top_k]], color=\"coral\", alpha=0.8)\n",
        "    axes[1].set_title(f\"Fine (bottom) code usage — top {top_k} most used codes\")\n",
        "    axes[1].set_xlabel(\"Rank (by usage)\")\n",
        "    axes[1].set_ylabel(\"Count\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_code_usage_histograms(counts_top, counts_bot, top_k=80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. t-SNE\n",
        "\n",
        "Run t-SNE on each of the four representations (z_top, z_bot, q_top, q_bot) to get 2D embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tsne = TSNE(n_components=2, perplexity=TSNE_PERPLEXITY, random_state=TSNE_RANDOM_STATE, n_iter=1000)\n",
        "\n",
        "emb_z_top = tsne.fit_transform(Z_top)\n",
        "emb_z_bot = tsne.fit_transform(Z_bot)\n",
        "emb_q_top = tsne.fit_transform(Q_top)\n",
        "emb_q_bot = tsne.fit_transform(Q_bot)\n",
        "\n",
        "print(\"t-SNE done for all four representations.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Plot 2×2 t-SNE panels\n",
        "\n",
        "Scatter plots colored by `machine_id` for pre-quant coarse/fine and post-quant coarse/fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_ids = sorted(set(machine_ids_subset))\n",
        "cmap = plt.cm.tab10\n",
        "colors = {mid: cmap(i % 10) for i, mid in enumerate(unique_ids)}\n",
        "color_vec = [colors[mid] for mid in machine_ids_subset]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "\n",
        "panels = [\n",
        "    (emb_z_top, \"Pre-quant coarse (z_top)\"),\n",
        "    (emb_z_bot, \"Pre-quant fine (z_bot)\"),\n",
        "    (emb_q_top, \"Post-quant coarse (q_top)\"),\n",
        "    (emb_q_bot, \"Post-quant fine (q_bot)\"),\n",
        "]\n",
        "for ax, (emb, title) in zip(axes.flat, panels):\n",
        "    for mid in unique_ids:\n",
        "        mask = [m == mid for m in machine_ids_subset]\n",
        "        ax.scatter(emb[mask, 0], emb[mask, 1], c=[colors[mid]], label=mid, alpha=0.6, s=15)\n",
        "    ax.set_title(title)\n",
        "    ax.legend(loc=\"best\", fontsize=8)\n",
        "    ax.set_aspect(\"equal\")\n",
        "\n",
        "plt.suptitle(f\"t-SNE by machine_id — {MACHINE_TYPE}, n={N}\", fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
