{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio-specific mask strategy analysis\n",
    "\n",
    "Compare **AudioSpecificStrategy** synthetic masks with **real anomaly patterns** from the DCASE test set (see `anomaly_spectrogram_study.ipynb`).\n",
    "\n",
    "Goals:\n",
    "- Recompute spatial localization of real anomalies (mean |anomaly − mean_normal| per machine type/ID).\n",
    "- Generate masks with **current** vs **proposed** parameters (one band, several time segments of consecutive frames).\n",
    "- Visualize masks at spectrogram size (n_mels × T) and resized to **q_shape** (q_top / q_bot spatial dims) used for codebook replacement.\n",
    "- Recommend parameter ranges so synthetic masks better match the anomalies seen in real spectrograms for different machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and data loading\n",
    "\n",
    "Reuse the same data loading as `anomaly_spectrogram_study.ipynb`: train (for normalization), test grouped by (machine_id, label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_cwd = Path(\".\").resolve()\n",
    "PROJECT_ROOT = _cwd.parent if _cwd.name == \"notebooks\" else _cwd\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.data.dataset import DCASE2020Task2LogMelDataset, DCASE2020Task2TestDataset\n",
    "from src.utils.anomalies.anomaly_map import AudioSpecificStrategy\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"dcase2020-task2-dev-dataset\"\n",
    "if not DATA_PATH.exists():\n",
    "    DATA_PATH = PROJECT_ROOT / \"../data/dcase2020-task2-dev-dataset\"\n",
    "\n",
    "MACHINE_TYPES = [\"fan\", \"pump\"]\n",
    "n_mels, T = 128, 320\n",
    "spectrogram_shape = (n_mels, T)\n",
    "\n",
    "def get_q_shape(n_mels: int, T: int) -> tuple[int, int]:\n",
    "    \"\"\"VQ-VAE 4× downsampling: H = n_mels//4, W = T//4.\"\"\"\n",
    "    return (max(1, n_mels // 4), max(1, T // 4))\n",
    "\n",
    "q_shape = get_q_shape(n_mels, T)\n",
    "print(f\"spectrogram_shape={spectrogram_shape}, q_shape={q_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_grouped(data_path: Path, machine_type: str):\n",
    "    \"\"\"Load train (for norm), test; group test by (machine_id, label).\"\"\"\n",
    "    train_ds = DCASE2020Task2LogMelDataset(\n",
    "        root=str(data_path), machine_type=machine_type, normalize=True\n",
    "    )\n",
    "    _, _, nm, Tm = train_ds.data.shape\n",
    "    test_ds = DCASE2020Task2TestDataset(\n",
    "        root=str(data_path), machine_type=machine_type,\n",
    "        mean=train_ds.mean, std=train_ds.std, target_T=train_ds.target_T,\n",
    "    )\n",
    "    grouped = defaultdict(lambda: {0: [], 1: []})\n",
    "    for idx in range(len(test_ds)):\n",
    "        spec, label, machine_id = test_ds[idx]\n",
    "        if spec.dim() == 3:\n",
    "            spec = spec.squeeze(0)\n",
    "        grouped[machine_id][label].append(spec.numpy())\n",
    "    return train_ds, test_ds, grouped, nm, Tm\n",
    "\n",
    "def stacked_by_id_label(grouped):\n",
    "    out = {}\n",
    "    for mid, by_label in grouped.items():\n",
    "        out[mid] = {\n",
    "            0: np.stack(by_label[0]) if by_label[0] else np.empty((0, 0, 0)),\n",
    "            1: np.stack(by_label[1]) if by_label[1] else np.empty((0, 0, 0)),\n",
    "        }\n",
    "    return out\n",
    "\n",
    "data_by_type = {}\n",
    "for mt in MACHINE_TYPES:\n",
    "    try:\n",
    "        train_ds, test_ds, grouped, nm, Tm = load_test_grouped(DATA_PATH, mt)\n",
    "        data_by_type[mt] = {\n",
    "            \"train_ds\": train_ds, \"test_ds\": test_ds, \"grouped\": grouped,\n",
    "            \"stacked\": stacked_by_id_label(grouped), \"n_mels\": nm, \"T\": Tm\n",
    "        }\n",
    "        print(f\"{mt}: n_mels={nm}, T={Tm}, IDs={sorted(grouped.keys())}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Skip {mt}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Real anomaly spatial localization\n",
    "\n",
    "For each (machine_type, machine_id): mean normal spectrogram, mean anomalous, and **dev** = mean over anomalous samples of |anomaly − mean_normal|. This shows which (mel, time) regions differ most in real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spatial_localization(stacked: dict, n_mels: int, T: int):\n",
    "    \"\"\"Per machine_id: mean_norm, mean_anom, diff, dev (spatial localization).\"\"\"\n",
    "    result = {}\n",
    "    for mid, arrs in stacked.items():\n",
    "        norm_arr = arrs[0]\n",
    "        anom_arr = arrs[1]\n",
    "        if norm_arr.size == 0 or anom_arr.size == 0:\n",
    "            continue\n",
    "        mean_norm = norm_arr.mean(axis=0)\n",
    "        mean_anom = anom_arr.mean(axis=0)\n",
    "        diff = mean_anom - mean_norm\n",
    "        dev = np.abs(anom_arr - mean_norm).mean(axis=0)\n",
    "        result[mid] = {\n",
    "            \"mean_norm\": mean_norm, \"mean_anom\": mean_anom,\n",
    "            \"diff\": diff, \"dev\": dev,\n",
    "            \"n_normal\": norm_arr.shape[0], \"n_anomaly\": anom_arr.shape[0],\n",
    "        }\n",
    "    return result\n",
    "\n",
    "real_localization = {}\n",
    "for mt in MACHINE_TYPES:\n",
    "    if mt not in data_by_type:\n",
    "        continue\n",
    "    st = data_by_type[mt][\"stacked\"]\n",
    "    nm, Tm = data_by_type[mt][\"n_mels\"], data_by_type[mt][\"T\"]\n",
    "    real_localization[mt] = compute_spatial_localization(st, nm, Tm)\n",
    "\n",
    "def print_deviation_summary(real_localization, n_mels, T):\n",
    "    for mt, by_id in real_localization.items():\n",
    "        print(f\"## {mt}\")\n",
    "        for mid, data in by_id.items():\n",
    "            dev = data[\"dev\"]\n",
    "            mel_peak = np.unravel_index(np.argmax(dev), dev.shape)[0]\n",
    "            time_peak = np.unravel_index(np.argmax(dev), dev.shape)[1]\n",
    "            band_frac = mel_peak / max(1, n_mels)\n",
    "            time_frac = time_peak / max(1, T)\n",
    "            diff = data[\"diff\"]\n",
    "            print(f\"  {mid}: peak at mel≈{mel_peak} ({band_frac:.2f}), time≈{time_peak} ({time_frac:.2f}); diff range [{diff.min():.3f}, {diff.max():.3f}]\")\n",
    "\n",
    "print_deviation_summary(real_localization, n_mels, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_real_localization(real_localization, machine_type: str, machine_id: str, n_mels: int, T: int):\n",
    "    if machine_type not in real_localization or machine_id not in real_localization[machine_type]:\n",
    "        return\n",
    "    data = real_localization[machine_type][machine_id]\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    axes[0].imshow(data[\"mean_norm\"], aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n",
    "    axes[0].set_title(f\"Mean normal ({machine_type} / {machine_id})\")\n",
    "    axes[0].set_ylabel(\"mel bin\")\n",
    "    axes[1].imshow(data[\"mean_anom\"], aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n",
    "    axes[1].set_title(\"Mean anomaly\")\n",
    "    axes[2].imshow(data[\"dev\"], aspect=\"auto\", origin=\"lower\", cmap=\"viridis\")\n",
    "    axes[2].set_title(\"Spatial localization: mean |anomaly − mean_norm|\")\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(\"time frame\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for mt in MACHINE_TYPES:\n",
    "    if mt not in real_localization:\n",
    "        continue\n",
    "    for mid in sorted(real_localization[mt].keys())[:2]:\n",
    "        plot_real_localization(real_localization, mt, mid, n_mels, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AudioSpecificStrategy: current vs proposed parameters\n",
    "\n",
    "- **Current**: one band (5–15% of n_mels), many segments (10–160), segment length up to T//4. This can produce very dense or scattered masks.\n",
    "- **Proposed (paper-like)**: **one band only**, **fewer time segments** (e.g. 3–20), each segment is a **consecutive block** of frames (random start, random length). The chosen band and segments are marked in M; M is then resized to q_shape for codebook replacement in q_top / q_bot.\n",
    "\n",
    "We generate masks at **spectrogram resolution** (n_mels × T) for comparison with real localization, then show the **resized** version (q_shape) used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio_specific_mask_spectrogram_size(\n",
    "    n_mels: int, T: int,\n",
    "    min_band_frac: float, max_band_frac: float,\n",
    "    min_segments: int, max_segments: int,\n",
    "    min_seg_len: int, max_seg_len: int,\n",
    "    seed: int | None = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate one mask at spectrogram size (n_mels, T).\n",
    "    One band; several time segments of consecutive frames (random start, random length).\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        import random\n",
    "        random.seed(seed)\n",
    "    M = np.zeros((n_mels, T), dtype=np.float32)\n",
    "    band_width = int(n_mels * np.random.uniform(min_band_frac, max_band_frac))\n",
    "    band_width = max(1, band_width)\n",
    "    f_low = np.random.randint(0, max(1, n_mels - band_width))\n",
    "    f_high = min(f_low + band_width, n_mels)\n",
    "    n_seg = np.random.randint(min_segments, max_segments + 1)\n",
    "    for _ in range(n_seg):\n",
    "        seg_len = np.random.randint(min_seg_len, min(max_seg_len + 1, T))\n",
    "        seg_len = max(1, seg_len)\n",
    "        t_start = np.random.randint(0, max(1, T - seg_len))\n",
    "        t_end = min(t_start + seg_len, T)\n",
    "        M[f_low:f_high, t_start:t_end] = 1.0\n",
    "    return M\n",
    "\n",
    "# Parameter presets\n",
    "CURRENT_PARAMS = {\n",
    "    \"min_band_fraction\": 0.05, \"max_band_fraction\": 0.15,\n",
    "    \"min_segments\": 10, \"max_segments\": 160,\n",
    "    \"min_seg_len\": 1, \"max_seg_len\": max(1, T // 4),\n",
    "}\n",
    "PROPOSED_PARAMS = {\n",
    "    \"min_band_fraction\": 0.05, \"max_band_fraction\": 0.20,\n",
    "    \"min_segments\": 3, \"max_segments\": 20,\n",
    "    \"min_seg_len\": 5, \"max_seg_len\": 60,\n",
    "}\n",
    "NARROW_BAND_FEW_SEGMENTS = {\n",
    "    \"min_band_fraction\": 0.03, \"max_band_fraction\": 0.10,\n",
    "    \"min_segments\": 2, \"max_segments\": 12,\n",
    "    \"min_seg_len\": 10, \"max_seg_len\": 80,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 6\n",
    "presets = {\n",
    "    \"current (many segments)\": CURRENT_PARAMS,\n",
    "    \"proposed (few segments, consecutive)\": PROPOSED_PARAMS,\n",
    "    \"narrow band, few segments\": NARROW_BAND_FEW_SEGMENTS,\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(len(presets), num_samples, figsize=(14, 3 * len(presets)))\n",
    "if len(presets) == 1:\n",
    "    axes = axes[np.newaxis, :]\n",
    "for i, (name, params) in enumerate(presets.items()):\n",
    "    for j in range(num_samples):\n",
    "        M = generate_audio_specific_mask_spectrogram_size(\n",
    "            n_mels, T,\n",
    "            params[\"min_band_fraction\"], params[\"max_band_fraction\"],\n",
    "            params[\"min_segments\"], params[\"max_segments\"],\n",
    "            params[\"min_seg_len\"], params[\"max_seg_len\"],\n",
    "            seed=None,\n",
    "        )\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(M, aspect=\"auto\", origin=\"lower\", cmap=\"gray\", vmin=0, vmax=1)\n",
    "        ax.set_xlabel(\"time\")\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(\"mel\")\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f\"{name}\\nmel\")\n",
    "        if i == 0:\n",
    "            ax.set_title(f\"Sample {j+1}\")\n",
    "plt.suptitle(\"Audio-specific masks at spectrogram size (n_mels × T)\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Same masks resized to q_shape (used in training)\n",
    "\n",
    "The model resizes M to q_shape (H_q × W_q) before applying codebook replacement to q_bot and q_top. Here we show the same parameter presets after resize to q_shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_mask_to_q(M: np.ndarray, q_shape: tuple[int, int]) -> np.ndarray:\n",
    "    \"\"\"M: (n_mels, T) or (1, 1, n_mels, T). Return (H_q, W_q).\"\"\"\n",
    "    t = torch.from_numpy(M).float()\n",
    "    if t.dim() == 2:\n",
    "        t = t.unsqueeze(0).unsqueeze(0)\n",
    "    t = F.interpolate(t, size=q_shape, mode=\"nearest\")\n",
    "    return t.squeeze().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(len(presets), num_samples, figsize=(14, 3 * len(presets)))\n",
    "if len(presets) == 1:\n",
    "    axes = axes[np.newaxis, :]\n",
    "for i, (name, params) in enumerate(presets.items()):\n",
    "    for j in range(num_samples):\n",
    "        M = generate_audio_specific_mask_spectrogram_size(\n",
    "            n_mels, T,\n",
    "            params[\"min_band_fraction\"], params[\"max_band_fraction\"],\n",
    "            params[\"min_segments\"], params[\"max_segments\"],\n",
    "            params[\"min_seg_len\"], params[\"max_seg_len\"],\n",
    "            seed=j + 42,\n",
    "        )\n",
    "        M_q = resize_mask_to_q(M, q_shape)\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(M_q, aspect=\"auto\", origin=\"lower\", cmap=\"gray\", vmin=0, vmax=1)\n",
    "        ax.set_xlabel(\"time (q)\")\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f\"{name}\\nfreq (q)\")\n",
    "        if i == 0:\n",
    "            ax.set_title(f\"q_shape {q_shape}\")\n",
    "plt.suptitle(\"Masks resized to q_shape (q_top / q_bot spatial dims)\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Side-by-side: real localization vs synthetic masks\n",
    "\n",
    "Compare one real spatial localization map (dev) with synthetic masks from the three presets for a chosen machine type / ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_type = \"fan\"\n",
    "machine_id = \"id_00\"\n",
    "if machine_type in real_localization and machine_id in real_localization[machine_type]:\n",
    "    dev = real_localization[machine_type][machine_id][\"dev\"]\n",
    "    n_rows = 1 + len(presets)\n",
    "    fig, axes = plt.subplots(n_rows, 4, figsize=(14, 3 * n_rows))\n",
    "    axes[0, 0].imshow(dev, aspect=\"auto\", origin=\"lower\", cmap=\"viridis\")\n",
    "    axes[0, 0].set_title(f\"Real: spatial localization\\n({machine_type} / {machine_id})\")\n",
    "    axes[0, 0].set_ylabel(\"mel\")\n",
    "    for k in range(1, 4):\n",
    "        axes[0, k].axis(\"off\")\n",
    "    for i, (name, params) in enumerate(presets.items()):\n",
    "        for j in range(4):\n",
    "            M = generate_audio_specific_mask_spectrogram_size(\n",
    "                n_mels, T,\n",
    "                params[\"min_band_fraction\"], params[\"max_band_fraction\"],\n",
    "                params[\"min_segments\"], params[\"max_segments\"],\n",
    "                params[\"min_seg_len\"], params[\"max_seg_len\"],\n",
    "                seed=j + 100 * (i + 1),\n",
    "            )\n",
    "            axes[i + 1, j].imshow(M, aspect=\"auto\", origin=\"lower\", cmap=\"gray\", vmin=0, vmax=1)\n",
    "            axes[i + 1, j].set_xlabel(\"time\")\n",
    "            if j == 0:\n",
    "                axes[i + 1, j].set_ylabel(f\"{name}\\nmel\")\n",
    "            if i == 0 and j > 0:\n",
    "                axes[i + 1, j].set_title(f\"Synthetic sample {j+1}\")\n",
    "    plt.suptitle(\"Real anomaly localization vs synthetic audio-specific masks\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"No data for {machine_type} / {machine_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using the actual AudioSpecificStrategy class\n",
    "\n",
    "Verify that the strategy class (with optional resizing to q_shape) produces masks consistent with the presets. The dataset can pass spectrogram_shape as q_shape so the mask stays at (n_mels, T); the model then resizes to q in `forward_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "strategy_current = AudioSpecificStrategy(\n",
    "    spectrogram_shape=spectrogram_shape,\n",
    "    q_shape=q_shape,\n",
    "    n_mels=n_mels,\n",
    "    T=T,\n",
    "    min_band_fraction=0.05,\n",
    "    max_band_fraction=0.15,\n",
    "    min_segments=10,\n",
    "    max_segments=160,\n",
    ")\n",
    "\n",
    "strategy_proposed = AudioSpecificStrategy(\n",
    "    spectrogram_shape=spectrogram_shape,\n",
    "    q_shape=q_shape,\n",
    "    n_mels=n_mels,\n",
    "    T=T,\n",
    "    min_band_fraction=0.05,\n",
    "    max_band_fraction=0.20,\n",
    "    min_segments=3,\n",
    "    max_segments=20,\n",
    ")\n",
    "\n",
    "M_current = strategy_current(4, device)\n",
    "M_proposed = strategy_proposed(4, device)\n",
    "print(f\"Current strategy output shape: {M_current.shape}\")  # (4, 1, H_q, W_q)\n",
    "print(f\"Proposed strategy output shape: {M_proposed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(14, 6))\n",
    "for j in range(4):\n",
    "    m = M_current[j, 0].numpy()\n",
    "    axes[0, j].imshow(m, aspect=\"auto\", origin=\"lower\", cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axes[0, j].set_title(f\"Current (q_shape) {j+1}\")\n",
    "    axes[0, j].set_xlabel(\"time\")\n",
    "for j in range(4):\n",
    "    m = M_proposed[j, 0].numpy()\n",
    "    axes[1, j].imshow(m, aspect=\"auto\", origin=\"lower\", cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axes[1, j].set_title(f\"Proposed (q_shape) {j+1}\")\n",
    "    axes[1, j].set_xlabel(\"time\")\n",
    "axes[0, 0].set_ylabel(\"current\\nfreq (q)\")\n",
    "axes[1, 0].set_ylabel(\"proposed\\nfreq (q)\")\n",
    "plt.suptitle(\"AudioSpecificStrategy outputs (resized to q_shape)\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and recommendations\n",
    "\n",
    "- **Real anomalies** (from the study): often localized in a specific frequency band and time region; deviation peak and extent vary by machine type and ID.\n",
    "- **Current AudioSpecificStrategy**: many segments (10–160) with short max length (T//4) can fill the band with a dense or scattered pattern that may not match real “one band + a few distinct segments” structure.\n",
    "- **Proposed**: **one band** (already the case), **fewer segments** (e.g. 3–20), **consecutive frames** per segment with min/max length (e.g. 5–60 or 10–80 frames). This better matches “anomalies in a band at several time intervals.”\n",
    "- **Mask flow**: M is generated at spectrogram size (n_mels × T), then resized to **q_shape** (H_q × W_q) for codebook replacement in q_bot and q_top. The dataset can return M at spectrogram size; the model resizes to q in `forward_train`.\n",
    "\n",
    "To align with the paper and real data, consider updating `AudioSpecificStrategy` defaults to something like: `min_segments=3`, `max_segments=20`, and segment length bounds (e.g. `min_seg_len=5`, `max_seg_len=60`) instead of a single `T//4` cap. You can also add explicit `min_seg_len` / `max_seg_len` parameters to the strategy constructor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
