{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly spectrogram study (Part 1)\n",
    "\n",
    "Characterize **where** and **how** real anomalies appear in the log-mel spectrogram, **per machine type and per machine_id**, to inform the anomaly generation module.\n",
    "\n",
    "- Load test set per machine type; group by `machine_id` and label (normal vs anomaly).\n",
    "- For each machine_id: mean normal spectrogram, mean anomalous spectrogram, difference heatmaps.\n",
    "- Spatial localization: mean |anomaly − mean_normal| over anomalous set.\n",
    "- Optional: per-band / per-frame stats and reconstruction residual (Stage 1 VQ-VAE).\n",
    "- Short summary per machine type for mask-prior design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and data loading\n",
    "\n",
    "Paths, imports, and load train/test datasets per machine type (train for normalization; test grouped by machine_id and label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "_cwd = Path(\".\").resolve()\n",
    "PROJECT_ROOT = _cwd.parent if _cwd.name == \"notebooks\" else _cwd\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data.dataset import DCASE2020Task2LogMelDataset, DCASE2020Task2TestDataset\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / \"../data/dcase2020-task2-dev-dataset\"\n",
    "MACHINE_TYPES = [\"fan\", \"pump\"]\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    DATA_PATH = PROJECT_ROOT / \"data/dcase2020-task2-dev-dataset\"\n",
    "print(f\"Data path: {DATA_PATH}, exists: {DATA_PATH.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_grouped_by_id_and_label(data_path: Path, machine_type: str):\n",
    "    \"\"\"Load train (for norm), then test; group test samples by (machine_id, label).\"\"\"\n",
    "    train_ds = DCASE2020Task2LogMelDataset(\n",
    "        root=str(data_path),\n",
    "        machine_type=machine_type,\n",
    "        normalize=True,\n",
    "    )\n",
    "    _, _, n_mels, T = train_ds.data.shape\n",
    "    test_ds = DCASE2020Task2TestDataset(\n",
    "        root=str(data_path),\n",
    "        machine_type=machine_type,\n",
    "        mean=train_ds.mean,\n",
    "        std=train_ds.std,\n",
    "        target_T=train_ds.target_T,\n",
    "    )\n",
    "    grouped = defaultdict(lambda: {0: [], 1: []})\n",
    "    for idx in range(len(test_ds)):\n",
    "        spec, label, machine_id = test_ds[idx]\n",
    "        if spec.dim() == 3:\n",
    "            spec = spec.squeeze(0)\n",
    "        grouped[machine_id][label].append(spec.numpy())\n",
    "    return train_ds, test_ds, grouped, n_mels, T\n",
    "\n",
    "def stacked_by_id_label(grouped):\n",
    "    \"\"\"Convert grouped dict to arrays: id -> {0: (N_norm, n_mels, T), 1: (N_anom, n_mels, T)}.\"\"\"\n",
    "    out = {}\n",
    "    for mid, by_label in grouped.items():\n",
    "        out[mid] = {\n",
    "            0: np.stack(by_label[0]) if by_label[0] else np.empty((0, 0, 0)),\n",
    "            1: np.stack(by_label[1]) if by_label[1] else np.empty((0, 0, 0)),\n",
    "        }\n",
    "    return out\n",
    "\n",
    "data_by_type = {}\n",
    "for mt in MACHINE_TYPES:\n",
    "    try:\n",
    "        train_ds, test_ds, grouped, n_mels, T = load_test_grouped_by_id_and_label(DATA_PATH, mt)\n",
    "        data_by_type[mt] = {\"train_ds\": train_ds, \"test_ds\": test_ds, \"grouped\": grouped,\n",
    "                            \"stacked\": stacked_by_id_label(grouped), \"n_mels\": n_mels, \"T\": T}\n",
    "        print(f\"{mt}: n_mels={n_mels}, T={T}, IDs={sorted(grouped.keys())}\")\n",
    "        for mid in sorted(grouped.keys()):\n",
    "            n_n, n_a = len(grouped[mid][0]), len(grouped[mid][1])\n",
    "            print(f\"  {mid}: normal={n_n}, anomaly={n_a}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Skip {mt}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mean spectrograms and difference heatmaps (per machine_id)\n",
    "\n",
    "For each machine type and machine_id: mean normal, mean anomalous, and difference (anomalous − normal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_and_diff(stacked, machine_type: str, machine_id: str, n_mels: int, T: int):\n",
    "    norm_arr = stacked[machine_id][0]\n",
    "    anom_arr = stacked[machine_id][1]\n",
    "    if norm_arr.size == 0 or anom_arr.size == 0:\n",
    "        return\n",
    "    mean_norm = norm_arr.mean(axis=0)\n",
    "    mean_anom = anom_arr.mean(axis=0)\n",
    "    diff = mean_anom - mean_norm\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    axes[0].imshow(mean_norm, aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n",
    "    axes[0].set_title(f\"Mean normal ({machine_type} {machine_id})\")\n",
    "    axes[0].set_xlabel(\"Time\")\n",
    "    axes[0].set_ylabel(\"Mel\")\n",
    "    axes[1].imshow(mean_anom, aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n",
    "    axes[1].set_title(f\"Mean anomalous\")\n",
    "    axes[1].set_xlabel(\"Time\")\n",
    "    axes[1].set_ylabel(\"Mel\")\n",
    "    v = np.abs(diff).max() or 1\n",
    "    axes[2].imshow(diff, aspect=\"auto\", origin=\"lower\", cmap=\"RdBu_r\", vmin=-v, vmax=v)\n",
    "    axes[2].set_title(\"Difference (anomalous − normal)\")\n",
    "    axes[2].set_xlabel(\"Time\")\n",
    "    axes[2].set_ylabel(\"Mel\")\n",
    "    plt.suptitle(f\"{machine_type} / {machine_id}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for mt, data in data_by_type.items():\n",
    "    stacked = data[\"stacked\"]\n",
    "    n_mels, T = data[\"n_mels\"], data[\"T\"]\n",
    "    for mid in sorted(stacked.keys()):\n",
    "        plot_mean_and_diff(stacked, mt, mid, n_mels, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spatial localization of deviation\n",
    "\n",
    "Per (machine_type, machine_id): mean |anomaly − mean_normal| over the anomalous set (which (mel, time) regions differ most)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_localization(stacked, machine_type: str, machine_id: str, n_mels: int, T: int):\n",
    "    norm_arr = stacked[machine_id][0]\n",
    "    anom_arr = stacked[machine_id][1]\n",
    "    if norm_arr.size == 0 or anom_arr.size == 0:\n",
    "        return\n",
    "    mean_norm = norm_arr.mean(axis=0)\n",
    "    dev = np.abs(anom_arr - mean_norm).mean(axis=0)\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    im = ax.imshow(dev, aspect=\"auto\", origin=\"lower\", cmap=\"hot\")\n",
    "    ax.set_title(f\"Spatial localization: mean |anomaly − mean_normal| ({machine_type} / {machine_id})\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Mel\")\n",
    "    plt.colorbar(im, ax=ax, label=\"Mean abs diff\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for mt, data in data_by_type.items():\n",
    "    stacked = data[\"stacked\"]\n",
    "    n_mels, T = data[\"n_mels\"], data[\"T\"]\n",
    "    for mid in sorted(stacked.keys()):\n",
    "        plot_localization(stacked, mt, mid, n_mels, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Per-band and per-frame statistics (optional)\n",
    "\n",
    "Mean energy per mel bin (over time) and per time frame (over mels) for normal vs anomaly; variance over time per band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_band_per_frame_stats(stacked, machine_id: str):\n",
    "    norm_arr = stacked[machine_id][0]\n",
    "    anom_arr = stacked[machine_id][1]\n",
    "    if norm_arr.size == 0 or anom_arr.size == 0:\n",
    "        return None\n",
    "    n_mels, T = norm_arr.shape[1], norm_arr.shape[2]\n",
    "    mean_norm_band = norm_arr.mean(axis=(0, 2))\n",
    "    mean_anom_band = anom_arr.mean(axis=(0, 2))\n",
    "    mean_norm_frame = norm_arr.mean(axis=(0, 1))\n",
    "    mean_anom_frame = anom_arr.mean(axis=(0, 1))\n",
    "    var_norm_band = norm_arr.var(axis=2).mean(axis=0)\n",
    "    var_anom_band = anom_arr.var(axis=2).mean(axis=0)\n",
    "    return {\n",
    "        \"mean_norm_band\": mean_norm_band, \"mean_anom_band\": mean_anom_band,\n",
    "        \"mean_norm_frame\": mean_norm_frame, \"mean_anom_frame\": mean_anom_frame,\n",
    "        \"var_norm_band\": var_norm_band, \"var_anom_band\": var_anom_band,\n",
    "        \"n_mels\": n_mels, \"T\": T,\n",
    "    }\n",
    "\n",
    "def plot_band_frame(stats, machine_type: str, machine_id: str):\n",
    "    if stats is None:\n",
    "        return\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 6))\n",
    "    m, T = stats[\"n_mels\"], stats[\"T\"]\n",
    "    axes[0].plot(stats[\"mean_norm_band\"], label=\"normal\")\n",
    "    axes[0].plot(stats[\"mean_anom_band\"], label=\"anomaly\")\n",
    "    axes[0].set_ylabel(\"Mean energy\")\n",
    "    axes[0].set_xlabel(\"Mel bin\")\n",
    "    axes[0].set_title(f\"Per-band mean ({machine_type} / {machine_id})\")\n",
    "    axes[0].legend()\n",
    "    axes[1].plot(stats[\"mean_norm_frame\"], label=\"normal\")\n",
    "    axes[1].plot(stats[\"mean_anom_frame\"], label=\"anomaly\")\n",
    "    axes[1].set_ylabel(\"Mean energy\")\n",
    "    axes[1].set_xlabel(\"Time frame\")\n",
    "    axes[1].set_title(\"Per-frame mean\")\n",
    "    axes[1].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for mt, data in data_by_type.items():\n",
    "    stacked = data[\"stacked\"]\n",
    "    for mid in sorted(stacked.keys()):\n",
    "        stats = per_band_per_frame_stats(stacked, mid)\n",
    "        plot_band_frame(stats, mt, mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reconstruction residual (optional)\n",
    "\n",
    "Encode normal and anomalous with trained Stage 1 VQ-VAE; decode; plot |input − reconstructed| to see what the model \"fails\" to represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = PROJECT_ROOT / \"checkpoints\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_stage1_if_available(machine_type: str, n_mels: int, T: int):\n",
    "    from src.models.vq_vae.autoencoders import VQ_VAE_2Layer\n",
    "    vq = VQ_VAE_2Layer(\n",
    "        num_hiddens=128,\n",
    "        num_residual_layers=2,\n",
    "        num_residual_hiddens=64,\n",
    "        num_embeddings=(1024, 4096),\n",
    "        embedding_dim=128,\n",
    "        commitment_cost=0.25,\n",
    "        decay=0.99,\n",
    "    )\n",
    "    ckpt = CKPT_DIR / \"stage1\" / machine_type / \"stage1_{}_best.pt\".format(machine_type)\n",
    "    if ckpt.exists():\n",
    "        state = torch.load(ckpt, map_location=\"cpu\", weights_only=True)\n",
    "        vq.load_state_dict(state[\"model_state_dict\"])\n",
    "    return vq.to(DEVICE).eval()\n",
    "\n",
    "def plot_reconstruction_residual(vq, stacked, machine_type: str, machine_id: str, n_mels: int, T: int, max_samples: int = 5):\n",
    "    norm_arr = stacked[machine_id][0]\n",
    "    anom_arr = stacked[machine_id][1]\n",
    "    if norm_arr.size == 0 or anom_arr.size == 0:\n",
    "        return\n",
    "    x_n = torch.from_numpy(norm_arr[:max_samples]).float().unsqueeze(1).to(DEVICE)\n",
    "    x_a = torch.from_numpy(anom_arr[:max_samples]).float().unsqueeze(1).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        q_bot_n, q_top_n = vq.encode(x_n)\n",
    "        rec_n = vq.decode_general(q_bot_n, q_top_n)\n",
    "        q_bot_a, q_top_a = vq.encode(x_a)\n",
    "        rec_a = vq.decode_general(q_bot_a, q_top_a)\n",
    "    res_n = (x_n - rec_n).abs().cpu().numpy()\n",
    "    res_a = (x_a - rec_a).abs().cpu().numpy()\n",
    "    mean_res_n = res_n.mean(axis=0).squeeze(0)\n",
    "    mean_res_a = res_a.mean(axis=0).squeeze(0)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    axes[0].imshow(mean_res_n, aspect=\"auto\", origin=\"lower\", cmap=\"hot\")\n",
    "    axes[0].set_title(f\"Mean |normal − recon| ({machine_type} / {machine_id})\")\n",
    "    axes[0].set_xlabel(\"Time\")\n",
    "    axes[0].set_ylabel(\"Mel\")\n",
    "    axes[1].imshow(mean_res_a, aspect=\"auto\", origin=\"lower\", cmap=\"hot\")\n",
    "    axes[1].set_title(f\"Mean |anomaly − recon|\")\n",
    "    axes[1].set_xlabel(\"Time\")\n",
    "    axes[1].set_ylabel(\"Mel\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for mt, data in data_by_type.items():\n",
    "    n_mels, T = data[\"n_mels\"], data[\"T\"]\n",
    "    vq = load_stage1_if_available(mt, n_mels, T)\n",
    "    if vq is None:\n",
    "        print(f\"No Stage1 checkpoint for {mt}; skip reconstruction residual.\")\n",
    "        continue\n",
    "    for mid in sorted(data[\"stacked\"].keys()):\n",
    "        plot_reconstruction_residual(vq, data[\"stacked\"], mt, mid, n_mels, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Short summary (for mask-prior design)\n",
    "\n",
    "Bullet list per machine type (or per ID): where anomalies tend to show (bands, regions, variance). Use this as prior for improving AudioSpecificStrategy / Perlin in the anomaly generation module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = {}\n",
    "for mt, data in data_by_type.items():\n",
    "    stacked = data[\"stacked\"]\n",
    "    n_mels, T = data[\"n_mels\"], data[\"T\"]\n",
    "    summaries[mt] = []\n",
    "    for mid in sorted(stacked.keys()):\n",
    "        norm_arr = stacked[mid][0]\n",
    "        anom_arr = stacked[mid][1]\n",
    "        if norm_arr.size == 0 or anom_arr.size == 0:\n",
    "            summaries[mt].append(f\"{mid}: no data\")\n",
    "            continue\n",
    "        mean_norm = norm_arr.mean(axis=0)\n",
    "        diff = anom_arr.mean(axis=0) - mean_norm\n",
    "        dev = np.abs(anom_arr - mean_norm).mean(axis=0)\n",
    "        mel_peak = np.unravel_index(np.argmax(dev), dev.shape)[0]\n",
    "        time_peak = np.unravel_index(np.argmax(dev), dev.shape)[1]\n",
    "        band_frac = mel_peak / max(1, n_mels)\n",
    "        time_frac = time_peak / max(1, T)\n",
    "        summaries[mt].append(\n",
    "            f\"{mid}: deviation peak at mel≈{mel_peak} ({band_frac:.2f}), time≈{time_peak} ({time_frac:.2f}); diff range [{diff.min():.3f}, {diff.max():.3f}].\"\n",
    "        )\n",
    "for mt in MACHINE_TYPES:\n",
    "    if mt not in summaries:\n",
    "        continue\n",
    "    print(f\"## {mt}\")\n",
    "    for s in summaries[mt]:\n",
    "        print(f\"- {s}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
